{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"","text":""},{"location":"#about","title":"About","text":"<p>LLM Agents Hub is prepared and maintained by the Framelab Research Group, part of the SWEN (Software Engineering) Research Group at the University of L\u2019Aquila. Our goal is to track high-signal, peer-reviewed and practitioner resources on agentic LLMs\u2014planning, tool use, multi-agent systems, evaluation, and productionization.</p> <p>We prioritize resources that are: reproducible, well-evaluated, and practically useful.</p>"},{"location":"#what-youll-find-here","title":"What you\u2019ll find here","text":"<ul> <li>Articles &amp; Surveys \u2014 seminal and state-of-the-art papers with 1\u20132 line annotations. \u2192 Browse</li> <li>Benchmarks \u2014 evaluation suites and leaderboards for agent capabilities. \u2192 Browse</li> <li>Frameworks \u2014 libraries for building agent systems. \u2192 Browse</li> <li>Repos \u2014 reference implementations and example systems. \u2192 Browse</li> <li>Industry Case Studies \u2014 deployments, postmortems, and best practices. \u2192 Browse</li> <li>Conferences &amp; Workshops \u2014 venues and recurring events relevant to agentic AI. \u2192 Browse</li> <li>Videos &amp; Talks \u2014 keynotes, tutorials, and deep dives. \u2192 Browse</li> <li>Datasets \u2014 corpora for training and evaluating agents. \u2192 Browse</li> <li>Newsletters \u2014 curated updates from the community. \u2192 Browse</li> </ul> <p>See our Taxonomy for tags and scope (e.g., <code>planning</code>, <code>tool-use</code>, <code>multi-agent</code>, <code>benchmark</code>, <code>production</code>, <code>security</code>).</p>"},{"location":"#contribute-a-resource","title":"Contribute a resource","text":"<p>We welcome PRs and suggestions\u2014especially with a short note on why it matters.</p> <p>\u2795 Suggest a resource Contribution Guide</p>"},{"location":"#curation-principles","title":"Curation principles","text":"<ul> <li>Quality over quantity \u2014 avoid duplicates and marketing-only content.  </li> <li>Reproducibility \u2014 code, data, and evaluation details preferred.  </li> <li>Signal \u2014 cite adoption, ablations, or comparative results when possible.  </li> <li>Safety &amp; reliability \u2014 include failure modes, guardrails, and cost/perf trade-offs.</li> </ul>"},{"location":"#roadmap","title":"Roadmap","text":"<ul> <li>\u2705 Basic taxonomy and section stubs  </li> <li>\u2705 Live spreadsheet integration  </li> <li>\u23f3 Seed each section with annotated examples</li> </ul>"},{"location":"articles/","title":"Papers","text":"Title Year Venue Notes ReAct: Synergizing Reasoning and Acting in Language Models 2025 \u2014 Software Engineering Becnhmark. Voyager: An Open-Ended Embodied Agent with LLMs 2025 \u2014 Software Engineering Agent."},{"location":"benchmarks/","title":"Benchmarks","text":"<p>A curated set of evaluation suites for LLM-based agents. These focus on goal-directed behavior such as web navigation, tool use, software engineering, and embodied/GUI tasks.</p> <p>Tip: when adding a new item, keep the description to one line and link to the canonical site or GitHub.</p> Name Description Link SWE-bench End-to-end software bug fixing on real GitHub repos/issues; success is verified by tests. https://www.swe-bench.com/ WebArena Sandbox of realistic websites for web agents; tasks span CRUD, search, navigation, and multi-step goals. https://webarena.dev/ Mind2Web Open-domain web navigation across real sites with natural-language instructions; tests generalization. https://github.com/OSU-NLP-Group/Mind2Web MiniWoB++ Suite of micro browser/GUI tasks (clicking, forms, navigation) for RL/agents. https://github.com/google/miniwob-plusplus ALFWorld Text-based household tasks (plan\u2013execute loops) built atop ALFRED; evaluates reasoning + action. https://github.com/alfworld/alfworld WebShop Goal-directed online shopping in a semi-structured e-commerce site; tests planning + tool use. https://github.com/princeton-nlp/WebShop AgentBench Multi-skill eval for agent capabilities (tool use, web, coding, etc.) with unified scoring. https://github.com/THUDM/AgentBench BrowserGym Gymnasium-compatible web-agent tasks for reproducible browser automation and evaluation. https://github.com/ServiceNow/BrowserGym"},{"location":"case-studies/","title":"Industry Case Studies","text":"<p>Real-world deployments of LLM-based agents and assistants across consumer apps and enterprises.</p> <p>Keep descriptions tight (one line) and link to the canonical source.</p> Name Description Link Klarna AI Assistant 24/7 customer-service agent deployed across markets; handles a large share of support chats end-to-end. https://www.klarna.com/international/press/klarna-ai-assistant-handles-two-thirds-of-customer-service-chats-in-its-first-month/ Duolingo Max GPT-4\u2013powered features (\u201cExplain My Answer\u201d, \u201cRoleplay\u201d) embedded in language learning. https://blog.duolingo.com/duolingo-max/ Khan Academy \u2014 Khanmigo AI tutor and teaching assistant piloted with teachers/students. https://blog.khanacademy.org/harnessing-ai-so-that-all-students-benefit-a-nonprofit-approach-for-equal-access/ Morgan Stanley Assistant Advisor assistant for retrieval and summarization over internal research/knowledge. https://openai.com/index/morgan-stanley/ Expedia \u2014 AI Trip Planning In-app travel planning assistant integrated with Expedia\u2019s shopping capabilities. https://www.expediagroup.com/investors/news-and-events/financial-releases/news/news-details/2023/Chatgpt-Wrote-This-Press-Release--No-It-Didnt-But-It-Can-Now-Assist-With-Travel-Planning-In-The-Expedia-App/default.aspx Shopify Sidekick Commerce assistant for merchants: answers questions and helps operate the store. https://www.shopify.com/news/summer-23-edition-100-updates-that-reimagine-commerce-for-the-future GitHub Copilot (Enterprise impact) Measured productivity/experience impact of AI assistance in the enterprise (study with Accenture). https://github.blog/news-insights/research/research-quantifying-github-copilots-impact-in-the-enterprise-with-accenture/ Notion AI Workspace-integrated AI (writing, summarize, Q&amp;A) rolled out broadly. https://www.notion.com/blog/notion-ai-is-here-for-everyone"},{"location":"conferences/","title":"Conferences &amp; Workshops","text":"<p>Recurring conferences and focused workshops that frequently feature LLM-based agents, tool use, web/navigation, multi-agent systems, and evaluation.</p> <p>Tip: link to the official site for each venue/workshop; keep descriptions to one line.</p> Name Description Link NeurIPS Premier ML venue; strong presence of agentic AI, RL, and many relevant workshops. :contentReference[oaicite:0]{index=0} https://neurips.cc/ ICML Top machine-learning conference; tutorials and workshops often cover agents, RL, and evaluation. :contentReference[oaicite:1]{index=1} https://icml.cc/ ICLR Focus on representation learning/deep learning; recent years include agent/LLM-agent workshops. :contentReference[oaicite:2]{index=2} https://iclr.cc/ ACL (Association for Computational Linguistics) Flagship NLP venue; many agent-adjacent topics (tool use, planning, dialogue). :contentReference[oaicite:3]{index=3} https://www.aclweb.org/ AAMAS Core conference for autonomous agents &amp; multiagent systems. :contentReference[oaicite:4]{index=4} https://www.ifaamas.org/ ICLR 2024 Workshop \u2014 LLM Agents Dedicated workshop on LLM-driven agents (methods, tasks, risks). :contentReference[oaicite:5]{index=5} https://llmagents.github.io/ NeurIPS 2024 Workshop \u2014 Towards Safe &amp; Trustworthy Agents Focused on safety/trustworthiness of agentic AI systems. :contentReference[oaicite:6]{index=6} https://neurips.cc/virtual/2024/workshop/84748 NeurIPS 2024 Workshop \u2014 Open-World Agents Reasoning + decision-making for open-world agents across diverse environments. :contentReference[oaicite:7]{index=7} https://neurips.cc/virtual/2024/workshop/84729 ICML 2024 Workshops (agent-related) Annual workshop program; several tracks touch agents, web navigation, safety, and evaluation. :contentReference[oaicite:8]{index=8} https://icml.cc/virtual/2024/events/workshop"},{"location":"datasets/","title":"Datasets","text":"<p>Datasets and interactive environments commonly used to evaluate or train LLM-based agents (web navigation, software engineering, embodied tasks, tool use).</p> <p>Keep descriptions to one line and link to the canonical site or GitHub.</p> Name Description Link SWE-bench End-to-end software bug fixing on real GitHub repos/issues; success verified by tests. :contentReference[oaicite:0]{index=0} https://www.swe-bench.com/ WebArena Self-hostable suite of realistic websites plus a benchmark for high-level web tasks. :contentReference[oaicite:1]{index=1} https://webarena.dev/ Mind2Web Generalist web-agent dataset with thousands of tasks across 100+ real sites/domains. :contentReference[oaicite:2]{index=2} https://osu-nlp-group.github.io/Mind2Web/ MiniWoB++ 100+ browser interaction micro-tasks; Gymnasium/Selenium interfaces. :contentReference[oaicite:3]{index=3} https://miniwob.farama.org/ WebShop Simulated e-commerce environment with 1.18M products and 12k+ instructions. :contentReference[oaicite:4]{index=4} https://webshop-pnlp.github.io/ ALFWorld Text-based tasks aligned to ALFRED for abstract planning before embodied execution. :contentReference[oaicite:5]{index=5} https://alfworld.github.io/ ALFRED Egocentric-vision household tasks mapping language \u2192 actions; leaderboard &amp; code. :contentReference[oaicite:6]{index=6} https://askforalfred.com/ ScienceWorld Text-based environment for elementary-science tasks and procedures. :contentReference[oaicite:7]{index=7} https://github.com/allenai/ScienceWorld OSWorld Real computer-use benchmark with hundreds of desktop/web tasks; actively updated. :contentReference[oaicite:8]{index=8} https://os-world.github.io/ ToolBench Large-scale tool-use instruction data to train/evaluate API-calling agents. :contentReference[oaicite:9]{index=9} https://github.com/OpenBMB/ToolBench"},{"location":"frameworks/","title":"Frameworks","text":"<p>Practical frameworks and libraries for building LLM-based agents: orchestration, tool-use, multi-agent patterns, memory/state, and evaluation.</p> <p>Keep descriptions to one line and link to the canonical repo or docs.</p> Name Description Link LangChain General LLM app framework with tools, chains, and agent abstractions used widely in production. :contentReference[oaicite:0]{index=0} https://github.com/langchain-ai/langchain LangGraph Low-level orchestration for stateful, long-running agents (checkpoints, cycles, human-in-the-loop). :contentReference[oaicite:1]{index=1} https://github.com/langchain-ai/langgraph AutoGen Microsoft\u2019s multi-agent framework for autonomous or human-in-the-loop agent apps. :contentReference[oaicite:2]{index=2} https://github.com/microsoft/autogen CrewAI Lean, high-performance multi-agent framework focused on role-based crews and control. :contentReference[oaicite:3]{index=3} https://github.com/crewAIInc/crewAI Semantic Kernel Model-agnostic SDK to build, orchestrate, and deploy AI agents and multi-agent systems. :contentReference[oaicite:4]{index=4} https://github.com/microsoft/semantic-kernel LlamaIndex Data framework for LLM apps with agent patterns over your data (Python + TS). :contentReference[oaicite:5]{index=5} https://github.com/run-llama/llama_index Haystack (Agents) End-to-end LLM framework; includes an Agent component for tool-use loops and web tasks. :contentReference[oaicite:6]{index=6} https://github.com/deepset-ai/haystack DSPy Declarative, self-improving programs for LMs\u2014useful as a backbone for agent loops and tooling. :contentReference[oaicite:7]{index=7} https://github.com/stanfordnlp/dspy Langroid Python framework with multi-agent programming as a first-class paradigm. :contentReference[oaicite:8]{index=8} https://github.com/langroid/langroid TaskWeaver Code-first agent framework for planning/executing data-analytics workflows via plugins. :contentReference[oaicite:9]{index=9} https://github.com/microsoft/TaskWeaver Griptape Python framework for agents, pipelines/workflows, and RAG with clean abstractions. :contentReference[oaicite:10]{index=10} https://github.com/griptape-ai/griptape AgentVerse (OpenBMB) Toolkit for deploying multiple LLM agents in task-solving or simulation settings. :contentReference[oaicite:11]{index=11} https://github.com/OpenBMB/AgentVerse CAMEL Open multi-agent framework/community exploring scaling laws of agents; libraries &amp; demos. :contentReference[oaicite:12]{index=12} https://github.com/camel-ai/camel"},{"location":"newsletters/","title":"Newsletters","text":"<p>Curated newsletters that frequently cover LLM-based agents (design, frameworks, evaluation, production).</p> Loading\u2026"},{"location":"repos/","title":"Agent Systems","text":"<p>Open-source LLM-based agent systems you can run end-to-end (autonomous loops, multi-tool workflows, coding agents, web agents, embodied agents).</p> <p>Keep descriptions to one line and link to the canonical repo/site.</p> Name Description Link Auto-GPT Early autonomous task runner with goals/memory/tools; kick-started the \u201cautonomous agent\u201d wave. https://github.com/Significant-Gravitas/AutoGPT BabyAGI Minimal, educational autonomous task loop that iteratively plans/executes tasks. https://github.com/yoheinakajima/babyagi OpenHands (ex-OpenDevin) Full software-dev agent platform: plans, edits, runs, and tests code in a real workspace. https://github.com/All-Hands-AI/OpenHands SWE-agent Automated bug-fixing/coding agent that works against real GitHub repos (tests verify success). https://github.com/SWE-agent/SWE-agent Open Interpreter Local \u201ccomputer control\u201d agent: runs code (Python/JS/Shell), automates your machine via chat. https://github.com/openinterpreter/open-interpreter OpenAgents Deployable multi-agent Web/Data/Chart agents with a hosted demo &amp; Vercel one-click. https://github.com/xlang-ai/OpenAgents browser-use Web-automation agent with MCP server; drive real browsers for navigation/forms/scraping. https://github.com/browser-use/browser-use Voyager (Minecraft) Open-ended embodied agent that explores, learns skills, and reuses a growing skill library. https://github.com/MineDojo/Voyager GPT Pilot \u201cAI developer\u201d agent that plans, codes, debugs, and iterates toward full features. https://github.com/Pythagora-io/gpt-pilot MetaGPT Multi-agent \u201csoftware company\u201d that turns a spec into artifacts (PM \u2192 design \u2192 code). https://github.com/FoundationAgents/MetaGPT"},{"location":"taxonomy/","title":"Taxonomy &amp; Tags","text":"<p>This page defines the controlled vocabulary we use across the hub so entries stay consistent and searchable. Use 3\u20137 tags per item, all lowercase, hyphen-separated (e.g., <code>tool-use</code>, <code>multi-agent</code>). Add a Tags column to tables where possible.</p>"},{"location":"taxonomy/#core-facets","title":"Core facets","text":""},{"location":"taxonomy/#1-agent-type","title":"1) Agent type","text":"<ul> <li><code>reactive</code> \u2014 single-step or short-horizon policies (no long planning)</li> <li><code>planner-executor</code> \u2014 explicit planning with an execution loop</li> <li><code>autonomous-loop</code> \u2014 self-driving loops (e.g., AutoGPT-style)</li> <li><code>multi-agent</code> \u2014 multiple coordinated agents / roles</li> <li><code>assistant</code> \u2014 human-in-the-loop assistants, copilots</li> </ul>"},{"location":"taxonomy/#2-capabilities","title":"2) Capabilities","text":"<ul> <li><code>planning</code>, <code>tool-use</code>, <code>retrieval</code>, <code>web-navigation</code>, <code>code-exec</code>, <code>apis</code>, <code>scheduling</code>, <code>vision</code>, <code>speech</code>, <code>translation</code></li> </ul>"},{"location":"taxonomy/#3-architecture-pattern","title":"3) Architecture / pattern","text":"<ul> <li><code>react</code> (reasoning + acting)</li> <li><code>reflexion</code> (self-reflection loops)</li> <li><code>tot</code> (tree-of-thought / search)</li> <li><code>langgraph</code>, <code>autogen</code>, <code>crewai</code>, <code>langchain</code>, <code>llamaindex</code> (framework patterns)</li> <li><code>function-calling</code>, <code>program-aided</code> (tool schemas / program induction)</li> </ul>"},{"location":"taxonomy/#4-memory","title":"4) Memory","text":"<ul> <li><code>short-term</code> (within prompt / context mgmt)</li> <li><code>long-term</code> (vector DB / episodic)</li> <li><code>tool-logs</code> (execution traces as memory)</li> </ul>"},{"location":"taxonomy/#5-environment-domain","title":"5) Environment / domain","text":"<ul> <li><code>web</code>, <code>browser</code>, <code>os-shell</code>, <code>ide</code>, <code>code</code>, <code>robotics</code>, <code>games</code>, <code>data</code>, <code>cloud</code>, <code>docs</code></li> </ul>"},{"location":"taxonomy/#6-evaluation-benchmarks","title":"6) Evaluation &amp; benchmarks","text":"<ul> <li><code>benchmark</code>, <code>task-success</code>, <code>cost</code>, <code>latency</code>, <code>robustness</code>, <code>safety-eval</code></li> <li>Specific suites as tags (when the paper centers on them): <code>alfworld</code>, <code>webarena</code>, <code>mind2web</code>, <code>swe-bench</code>, <code>miniwob</code>, <code>webshop</code>, <code>hotpotqa</code></li> </ul>"},{"location":"taxonomy/#7-production-safety","title":"7) Production &amp; safety","text":"<ul> <li><code>guardrails</code>, <code>monitoring</code>, <code>red-teaming</code>, <code>prompt-security</code>, <code>eval-in-prod</code>, <code>cost-control</code>, <code>privacy</code></li> </ul>"},{"location":"taxonomy/#tagging-rules","title":"Tagging rules","text":"<ol> <li>Pick one primary type (<code>reactive</code>, <code>planner-executor</code>, <code>autonomous-loop</code>, <code>multi-agent</code>, or <code>assistant</code>).  </li> <li>Add 2\u20134 capability tags (e.g., <code>tool-use</code>, <code>planning</code>, <code>web-navigation</code>).  </li> <li>Add architecture tags if the work proposes/uses one (e.g., <code>react</code>, <code>reflexion</code>, <code>langgraph</code>).  </li> <li>If the work evaluates on a known suite, include the benchmark tag (e.g., <code>swe-bench</code>).  </li> <li>If the paper is about operational concerns, add production/safety tags (<code>monitoring</code>, <code>guardrails</code>, \u2026).</li> </ol> <p>Keep tags short; prefer hyphenated single tokens (e.g., <code>tool-use</code>, not <code>Tool Use</code>).</p>"},{"location":"taxonomy/#examples","title":"Examples","text":""},{"location":"taxonomy/#paper-entry-table-row","title":"Paper entry (table row)","text":"Title Year Venue Tags Notes ReAct: Synergizing Reasoning and Acting in Language Models 2022 \u2014 <code>react</code>, <code>planner-executor</code>, <code>tool-use</code> Introduces the ReAct pattern combining CoT + tool calls. Voyager: An Open-Ended Embodied Agent with LLMs 2023 \u2014 <code>autonomous-loop</code>, <code>memory</code>, <code>code-exec</code> Skill library; continual learning in Minecraft. SWE-bench 2023 \u2014 <code>benchmark</code>, <code>code</code>, <code>swe-bench</code>, <code>task-success</code> End-to-end code-fix benchmark for LLM agents."},{"location":"taxonomy/#repo-framework-entry","title":"Repo / framework entry","text":"Name Link Tags Notes LangGraph https://github.com/langchain-ai/langgraph <code>langgraph</code>, <code>planner-executor</code>, <code>tool-logs</code> Graph-based control for agents with state &amp; memory. AutoGen https://github.com/microsoft/autogen <code>autogen</code>, <code>multi-agent</code>, <code>assistant</code> Multi-agent chat orchestration patterns."},{"location":"taxonomy/#controlled-tag-list-cheat-sheet","title":"Controlled tag list (cheat sheet)","text":"<p>Types: <code>reactive</code>, <code>planner-executor</code>, <code>autonomous-loop</code>, <code>multi-agent</code>, <code>assistant</code> Capabilities: <code>planning</code>, <code>tool-use</code>, <code>retrieval</code>, <code>web-navigation</code>, <code>code-exec</code>, <code>apis</code>, <code>vision</code>, <code>speech</code>, <code>translation</code>, <code>scheduling</code> Architecture: <code>react</code>, <code>reflexion</code>, <code>tot</code>, <code>function-calling</code>, <code>program-aided</code>, <code>langgraph</code>, <code>autogen</code>, <code>crewai</code>, <code>langchain</code>, <code>llamaindex</code> Memory: <code>short-term</code>, <code>long-term</code>, <code>tool-logs</code> Environment: <code>web</code>, <code>browser</code>, <code>os-shell</code>, <code>ide</code>, <code>code</code>, <code>robotics</code>, <code>games</code>, <code>data</code>, <code>cloud</code>, <code>docs</code> Eval/Benchmarks: <code>benchmark</code>, <code>task-success</code>, <code>robustness</code>, <code>cost</code>, <code>latency</code>, <code>safety-eval</code>, <code>alfworld</code>, <code>webarena</code>, <code>mind2web</code>, <code>miniwob</code>, <code>webshop</code>, <code>swe-bench</code>, <code>hotpotqa</code> Prod &amp; Safety: <code>guardrails</code>, <code>monitoring</code>, <code>red-teaming</code>, <code>prompt-security</code>, <code>eval-in-prod</code>, <code>cost-control</code>, <code>privacy</code></p>"},{"location":"taxonomy/#how-to-use-tags-in-pages","title":"How to use tags in pages","text":"<ul> <li>Add a Tags column to your tables (recommended).  </li> <li>Or add inline chips after each item, e.g.: <code>&lt;span class=\"tag\"&gt;planner-executor&lt;/span&gt; &lt;span class=\"tag tag--capability\"&gt;tool-use&lt;/span&gt;</code></li> </ul> <p>See styling below.</p>"},{"location":"videos/","title":"Videos &amp; Talks","text":""}]}